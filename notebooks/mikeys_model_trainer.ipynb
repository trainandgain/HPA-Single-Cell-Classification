{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-garbage",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "metallic-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = ['red', 'green', 'blue', 'yellow']\n",
    "TRAIN_CSV = 'D:/HPA_comp/single_cells/train_folds.csv'\n",
    "IMG_DIR = 'D:/HPA_comp/single_cells'\n",
    "MEAN_CHANNEL_VALUES = (0.07730, 0.05958, 0.07135)  # RGB\n",
    "CHANNEL_STD_DEV = (0.12032, 0.08593, 0.14364)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-brain",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "familiar-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "\n",
    "class CellDataset(object):\n",
    "    '''Dataset class to fetch HPA cell-level images\n",
    "    and corresponding weak labels\n",
    "    '''\n",
    "    def __init__(self, images, targets, img_root, augmentations=None):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.img_root = img_root\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.images[idx] \n",
    "        img_channels = self._fetch_channels(img_id)\n",
    "        img = self._channels_2_array(img_channels)\n",
    "        img = resize(img, (224, 224))  # Always resize cell images for collate function\n",
    "        # If augmentation pipeline provided, apply augmentations\n",
    "        if self.augmentations:\n",
    "            img = self.augmentations(image=img)['image']\n",
    "        # Adjust to channel first indexing for pytorch (speed reasons)\n",
    "        features = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "        target = self.targets[idx]  # Grab target vector\n",
    "        \n",
    "        return {'image': torch.tensor(features),\n",
    "                'target': torch.tensor(target)\n",
    "                }\n",
    "    \n",
    "    def _fetch_channels(self, img_id: str, channel_names=CHANNELS):\n",
    "        'Return absolute path of segmentation channels of a given image id'\n",
    "        base = os.path.join(self.img_root, img_id)\n",
    "        return [base + '_' + i  + '.png' for i in channel_names]\n",
    "                                         \n",
    "    def _channels_2_array(self, img_channels):\n",
    "        'Return 3D array of pixel values of input image channels'\n",
    "        r = imageio.imread(img_channels[0])\n",
    "        g = imageio.imread(img_channels[1])\n",
    "        b = imageio.imread(img_channels[2])\n",
    "        pixel_arr = np.dstack((r, g, b))\n",
    "        return pixel_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-sensitivity",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "distant-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tez\n",
    "\n",
    "class ResNet18(tez.Model):\n",
    "    '''Model class to facilitate transfer learning \n",
    "    from a resnet-18 model\n",
    "    '''\n",
    "    NUM_CLASSES = 19\n",
    "    DROPOUT_RATE = 0.1\n",
    "    IMG_DIR = 'D:/HPA_comp/single_cells'\n",
    "    \n",
    "    def __init__(self, train_df, valid_df, batch_size=16, train_aug=None, valid_aug=None, pretrained=True):\n",
    "        # Initialise pretrained net and final layers for cell classification\n",
    "        super().__init__()\n",
    "        self.convolutions = nn.Sequential(*(list(resnet18(pretrained).children())[0:-1]))\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "        self.dense = nn.Linear(512, self.NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        \n",
    "        # Below should probably be in tez.Model super class but is a quick hack around\n",
    "        # Training time image augmentation stack\n",
    "        self.train_loader = self.gen_dataloader(train_df, batch_size, shuffle=True, aug=train_aug)\n",
    "        self.valid_loader = self.gen_dataloader(valid_df, batch_size, shuffle=False, aug=valid_aug)\n",
    "        \n",
    "    def forward(self, image, target=None):\n",
    "        batch_size = image.shape[0]\n",
    "        \n",
    "        # Extracts 512x1 feature vector from pretrained resnet18 conv layers\n",
    "        x = self.convolutions(image).reshape(batch_size, -1)\n",
    "        # Fully connected dense layer to 19 class output\n",
    "        output = self.dense(self.dropout(x))\n",
    "        # Sigmoid activations on output to infer class probabilities\n",
    "        output_probs = self.out(output)\n",
    "        \n",
    "        if target is not None:\n",
    "            loss = self.loss_fn(output_probs, target.to(torch.float32))  # why to float32???\n",
    "            metrics = self.monitor_metrics(output_probs, target)\n",
    "            return output_probs, loss, metrics\n",
    "        return output_probs, None, None\n",
    "    \n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        if targets is None:\n",
    "            return {}\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        precision = average_precision_score(targets, outputs, average=None)\n",
    "        #accuracy = accuracy_score(targets, outputs)\n",
    "        #precision = 1\n",
    "        return {\"precision\": precision}\n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return opt\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "        )\n",
    "        return sch\n",
    "    \n",
    "    def gen_dataloader(self, df, bs, shuffle, aug=None):\n",
    "        'Return pytorch dataloader generated from cell image dataframe'\n",
    "        # Extract images and targets as numpy arrays from dataframe tranche\n",
    "        def extract_as_array(str_):\n",
    "            list_ = str_.strip('][').split(', ')\n",
    "            return np.array([int(i) for i in list_])\n",
    "        images = df['cell_id'].values\n",
    "        targets = df['Label'].apply(extract_as_array).values\n",
    "        # Init custom dataset class and pass to pytorch\n",
    "        dataset = CellDataset(images, targets, self.IMG_DIR, aug)\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-investigation",
   "metadata": {},
   "source": [
    "## if __name__ == '__main__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thorough-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# Image augmentation stack \n",
    "train_aug = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(\n",
    "        mean=MEAN_CHANNEL_VALUES,\n",
    "        std=CHANNEL_STD_DEV,\n",
    "        max_pixel_value=1.0,\n",
    "        p=1.0\n",
    "    )\n",
    "])\n",
    " \n",
    "valid_aug = A.Compose([\n",
    "    A.Normalize(\n",
    "        mean=MEAN_CHANNEL_VALUES,\n",
    "        std=CHANNEL_STD_DEV,\n",
    "        max_pixel_value=1.0,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "broad-angel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1391/1391 [16:20<00:00,  1.42it/s, loss=0.202, precision=1, stage=train]\n",
      "100%|██████████████████████████████████████████████████████████████████| 346/346 [03:48<00:00,  1.51it/s, loss=0.188, precision=1, stage=valid]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (inf --> 0.1880082305025503). Saving model!\n"
     ]
    }
   ],
   "source": [
    "# Select training folds from csv\n",
    "dfx = pd.read_csv(TRAIN_CSV, index_col=0)\n",
    "FOLD = 0\n",
    "#df_train, df_valid = df.iloc[:30, :] , df.iloc[30:, :]\n",
    "df_train = dfx[dfx['fold'] != FOLD].reset_index(drop=True)\n",
    "df_valid = dfx[dfx['fold'] == FOLD].reset_index(drop=True)\n",
    "\n",
    "# Init model\n",
    "model = ResNet18(\n",
    "     df_train, \n",
    "     df_valid, \n",
    "     batch_size=16, \n",
    "     train_aug=train_aug, \n",
    "     valid_aug=valid_aug, \n",
    "     pretrained=True\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "from tez.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='valid_loss',\n",
    "    model_path='../models/model_checkpoint.bin',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Model training\n",
    "model.fit(\n",
    "    train_dataset=None,  # dataset inits are overriden in the model class above\n",
    "    valid_dataset=None,  # otherwise tez breaks for me when it tries to do this itself\n",
    "    train_bs=16,\n",
    "    device='cuda',\n",
    "    callbacks=[es],\n",
    "    epochs=1\n",
    ")\n",
    "\n",
    "# Save model (with optimizer and scheduler for future usage)\n",
    "model.save('../models/trained_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "experimental-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_number</th>\n",
       "      <th>edge_of_img</th>\n",
       "      <th>parent_image_id</th>\n",
       "      <th>size_x</th>\n",
       "      <th>size_y</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27766</th>\n",
       "      <td>15029c6e-bb9c-11e8-b2b9-ac1f6b6435d0_cell_8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15029c6e-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27767</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27768</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27769</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27770</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27771</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27772</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>628.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27773</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27774</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27775</th>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cell_id  cell_number  edge_of_img  \\\n",
       "27766  15029c6e-bb9c-11e8-b2b9-ac1f6b6435d0_cell_8          8.0          0.0   \n",
       "27767  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_1          1.0          1.0   \n",
       "27768  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_2          2.0          0.0   \n",
       "27769  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_3          3.0          0.0   \n",
       "27770  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_4          4.0          0.0   \n",
       "27771  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_5          5.0          0.0   \n",
       "27772  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_6          6.0          0.0   \n",
       "27773  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_7          7.0          0.0   \n",
       "27774  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_8          8.0          1.0   \n",
       "27775  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0_cell_9          9.0          0.0   \n",
       "\n",
       "                            parent_image_id  size_x  size_y  \\\n",
       "27766  15029c6e-bb9c-11e8-b2b9-ac1f6b6435d0   468.0   850.0   \n",
       "27767  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   358.0   494.0   \n",
       "27768  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   332.0   508.0   \n",
       "27769  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   336.0   428.0   \n",
       "27770  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   276.0   376.0   \n",
       "27771  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   268.0   255.0   \n",
       "27772  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   628.0   604.0   \n",
       "27773  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   276.0   267.0   \n",
       "27774  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   262.0   388.0   \n",
       "27775  14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0   336.0   408.0   \n",
       "\n",
       "                                                   Label  \n",
       "27766  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "27767  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27768  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27769  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27770  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27771  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27772  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27773  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27774  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
       "27775  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/HPA_comp/single_cells/train.csv', index_col=0)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "solved-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c27f04c-bb99-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>8|5|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fb643ee-bb99-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>14|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60b57878-bb99-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>6|1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c1a898e-bb99-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>16|10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b931256-bb99-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>14|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21802</th>\n",
       "      <td>dd1f7fb8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>3|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21803</th>\n",
       "      <td>dd5cb36a-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>14|0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21804</th>\n",
       "      <td>df573730-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21805</th>\n",
       "      <td>dea19dc6-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5|0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ID  Label\n",
       "0      5c27f04c-bb99-11e8-b2b9-ac1f6b6435d0  8|5|0\n",
       "1      5fb643ee-bb99-11e8-b2b9-ac1f6b6435d0   14|0\n",
       "2      60b57878-bb99-11e8-b2b9-ac1f6b6435d0    6|1\n",
       "3      5c1a898e-bb99-11e8-b2b9-ac1f6b6435d0  16|10\n",
       "4      5b931256-bb99-11e8-b2b9-ac1f6b6435d0   14|0\n",
       "...                                     ...    ...\n",
       "21801  dd0989c4-bbca-11e8-b2bc-ac1f6b6435d0     14\n",
       "21802  dd1f7fb8-bbca-11e8-b2bc-ac1f6b6435d0    3|0\n",
       "21803  dd5cb36a-bbca-11e8-b2bc-ac1f6b6435d0   14|0\n",
       "21804  df573730-bbca-11e8-b2bc-ac1f6b6435d0     14\n",
       "21805  dea19dc6-bbca-11e8-b2bc-ac1f6b6435d0    5|0\n",
       "\n",
       "[21806 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/HPA_comp/train/train.csv')\n",
    "df['ID'] == '14c9a968-bb9c-11e8-b2b9-ac1f6b6435d0'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
