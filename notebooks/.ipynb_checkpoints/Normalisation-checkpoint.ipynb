{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-google",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = ['red', 'green', 'blue', 'yellow']\n",
    "TRAIN_CSV = '../input/image_subset/cell/train.csv'\n",
    "IMG_DIR = '../input/image_subset/cell/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellDataset(object):\n",
    "    '''Dataset class to fetch HPA cell-level images\n",
    "    and corresponding weak labels\n",
    "    '''\n",
    "    def __init__(self, images, targets, img_root, augmentations=None):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.img_root = img_root\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.images[idx] \n",
    "        img_channels = self._fetch_channels(img_id)\n",
    "        img = self._channels_2_array(img_channels)\n",
    "        img = resize(img, (224, 224))  # Always resize cell images for collate function\n",
    "        # If augmentation pipeline provided, apply augmentations\n",
    "        if self.augmentations:\n",
    "            img = self.augmentations(image=img)['image']\n",
    "        # Adjust to channel first indexing for pytorch (speed reasons)\n",
    "        features = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "        target = self.targets[idx]  # Grab target vector\n",
    "        \n",
    "        return {'image': torch.tensor(features),\n",
    "                'target': torch.tensor(target)\n",
    "                }\n",
    "    \n",
    "    def _fetch_channels(self, img_id: str, channel_names=CHANNELS):\n",
    "        'Return absolute path of segmentation channels of a given image id'\n",
    "        base = os.path.join(self.img_root, img_id)\n",
    "        return [base + '_' + i  + '.png' for i in channel_names]\n",
    "                                         \n",
    "    def _channels_2_array(self, img_channels):\n",
    "        'Return 3D array of pixel values of input image channels'\n",
    "        r = imageio.imread(img_channels[0])\n",
    "        g = imageio.imread(img_channels[1])\n",
    "        b = imageio.imread(img_channels[2])\n",
    "        pixel_arr = np.dstack((r, g, b))\n",
    "        return pixel_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataloader(df, img_dir, bs, shuffle, aug=None):\n",
    "        'Return pytorch dataloader generated from cell image dataframe'\n",
    "        # Extract images and targets as numpy arrays from dataframe tranche\n",
    "        def extract_as_array(str_):\n",
    "            list_ = str_.strip('][').split(', ')\n",
    "            return np.array([int(i) for i in list_])\n",
    "        images = df['cell_id'].values\n",
    "        targets = df['Label'].apply(extract_as_array).values\n",
    "        # Init custom dataset class and pass to pytorch\n",
    "        dataset = CellDataset(images, targets, img_dir, aug)\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_pixel_aggs(dataloader, sample_size):\n",
    "    'Return dataframe of image channel means and standard deviations'\n",
    "    aggs_df = pd.DataFrame()\n",
    "    \n",
    "    for count, sample in enumerate(dataloader):\n",
    "        image_tensor = sample['image']  # indexed by (C, H, W)\n",
    "        aggs = {}\n",
    "        # Grab cell image channel aggregates\n",
    "        channels = ['red', 'green', 'blue']\n",
    "        for idx, channel_name in enumerate(channels):\n",
    "            channel = image_tensor[0, idx, :, :]\n",
    "            min_value = channel.min().item()\n",
    "            max_value = channel.max().item()\n",
    "            mean = channel.mean().item()\n",
    "            std = channel.std().item()\n",
    "            aggs[channel_name + '_max'] = max_value\n",
    "            aggs[channel_name + '_min'] = min_value\n",
    "            aggs[channel_name + '_mean'] = mean\n",
    "            aggs[channel_name + '_std'] = std\n",
    "        aggs_df = aggs_df.append(aggs, ignore_index=True)\n",
    "        if count >= sample_size:\n",
    "            break\n",
    "    return aggs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV, index_col=0)\n",
    "loader = gen_dataloader(df, img_dir=IMG_DIR, bs=1, shuffle=True, aug=None)\n",
    "aggs_df = grab_pixel_aggs(loader, sample_size=1000)\n",
    "aggs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-module",
   "metadata": {},
   "source": [
    "## Magic Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Red channel mean:   {aggs_df.red_mean.mean()}')\n",
    "print(f'Red std dev:   {aggs_df.red_std.mean()}')\n",
    "print(f'Green channel mean:   {aggs_df.green_mean.mean()}')\n",
    "print(f'Green std dev:   {aggs_df.green_std.mean()}')\n",
    "print(f'Blue channel mean:   {aggs_df.blue_mean.mean()}')\n",
    "print(f'Blue std dev:   {aggs_df.blue_std.mean()}')\n",
    "print('Global max:   ?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell]",
   "language": "python",
   "name": "conda-env-cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
