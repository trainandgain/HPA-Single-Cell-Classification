{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false
   },
   "source": [
    "# Submission Template\n",
    "\n",
    "So for submission this is how it is going to look:\n",
    "\n",
    "\n",
    "<code>ID Width Height Predicition_String</code>\n",
    "\n",
    "Where Prediction string is:\n",
    "\n",
    "<code>0_class cell_0_class_prob cell_0_rle_binary_mask_encoded\n",
    "1_class cell_0_class_prob cell_0_rle_binary_mask_encoded\n",
    "2_class cell_0_class_prob cell_0_rle_binary_mask_encoded    \n",
    "3_class cell_0_class_prob cell_0_rle_binary_mask_encoded\n",
    "4_class cell_0_class_prob cell_0_rle_binary_mask_encoded\n",
    "5_class cell_0_class_prob cell_0_rle_binary_mask_encoded\n",
    "6_class cell_0_class_prob cell_0_rle_binary_mask_encoded    \n",
    "7_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "8_class cell_0_class_prob cell_0_rle_binary_mask_encoded \n",
    "9_class cell_0_class_prob cell_0_rle_binary_mask_encoded \n",
    "10_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "11_class cell_0_class_prob cell_0_rle_binary_mask_encoded    \n",
    "12_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "13_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "14_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "15_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "16_class cell_0_class_prob cell_0_rle_binary_mask_encoded \n",
    "17_class cell_0_class_prob cell_0_rle_binary_mask_encoded     \n",
    "18_class cell_0_class_prob cell_0_rle_binary_mask_encoded</code>     \n",
    "    \n",
    "<code>0_class cell_1_class_prob cell_1_rle_binary_mask_encoded\n",
    "1_class cell_1_class_prob cell_1_rle_binary_mask_encoded\n",
    "2_class cell_1_class_prob cell_1_rle_binary_mask_encoded    \n",
    "3_class cell_1_class_prob cell_1_rle_binary_mask_encoded\n",
    "4_class cell_1_class_prob cell_1_rle_binary_mask_encoded\n",
    "5_class cell_1_class_prob cell_1_rle_binary_mask_encoded\n",
    "6_class cell_1_class_prob cell_1_rle_binary_mask_encoded    \n",
    "7_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "8_class cell_1_class_prob cell_1_rle_binary_mask_encoded \n",
    "9_class cell_1_class_prob cell_1_rle_binary_mask_encoded \n",
    "10_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "11_class cell_1_class_prob cell_1_rle_binary_mask_encoded    \n",
    "12_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "13_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "14_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "15_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "16_class cell_1_class_prob cell_1_rle_binary_mask_encoded \n",
    "17_class cell_1_class_prob cell_1_rle_binary_mask_encoded     \n",
    "18_class cell_1_class_prob cell_1_rle_binary_mask_encoded</code>         \n",
    "    \n",
    "    \n",
    "...\n",
    "\n",
    "<code>0_class cell_n_class_prob cell_n_rle_binary_mask_encoded\n",
    "1_class cell_n_class_prob cell_n_rle_binary_mask_encoded\n",
    "2_class cell_n_class_prob cell_n_rle_binary_mask_encoded    \n",
    "3_class cell_n_class_prob cell_n_rle_binary_mask_encoded\n",
    "4_class cell_n_class_prob cell_n_rle_binary_mask_encoded\n",
    "5_class cell_n_class_prob cell_n_rle_binary_mask_encoded\n",
    "6_class cell_n_class_prob cell_n_rle_binary_mask_encoded    \n",
    "7_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "8_class cell_n_class_prob cell_n_rle_binary_mask_encoded \n",
    "9_class cell_n_class_prob cell_n_rle_binary_mask_encoded \n",
    "10_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "11_class cell_n_class_prob cell_n_rle_binary_mask_encoded    \n",
    "12_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "13_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "14_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "15_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "16_class cell_n_class_prob cell_n_rle_binary_mask_encoded \n",
    "17_class cell_n_class_prob cell_n_rle_binary_mask_encoded     \n",
    "18_class cell_n_class_prob cell_n_rle_binary_mask_encoded</code>     \n",
    "    \n",
    "    \n",
    "    \n",
    "So as you can see, It is going to be pretty long.\n",
    "\n",
    "The sample_submission.csv contains all the test folder ID's so all we need to do is predict on all of those images in the above format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tez_path = '../input/dyno-pytorch'\n",
    "import sys\n",
    "sys.path.append(tez_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pixel normalisation\n",
    "MEAN_CHANNEL_VALUES=(0.485, 0.456, 0.406)\n",
    "CHANNEL_STD_DEV=(0.229, 0.224, 0.225)\n",
    "#MEAN_CHANNEL_VALUES = (0.07730, 0.05958, 0.07135)  # RGB\n",
    "#CHANNEL_STD_DEV = (0.12032, 0.08593, 0.14364)\n",
    "\n",
    "# Path to weights\n",
    "MODEL_PATH = '../input/models/model_split_0.bin'\n",
    "RESNET_PATH = '../input/models/resnet18.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n",
    "!pip install -q \"../input/hpapytorchzoozip/pytorch_zoo-master\"\n",
    "!pip install -q \"../input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd \n",
    "import base64\n",
    "import numpy as np\n",
    "from pycocotools import _mask as coco_mask\n",
    "from typing import List, Tuple\n",
    "import zlib\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "import tez\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "# HPA\n",
    "import os\n",
    "import imageio\n",
    "from hpacellseg.cellsegmentator import CellSegmentator\n",
    "from hpacellseg.utils import label_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please compile abn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'pytorch_zoo.unet.DPNUnet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import hpacellseg.cellsegmentator as cellsegmentator\n",
    "from hpacellseg.utils import label_cell, label_nuclei\n",
    "\n",
    "NUC_MODEL = '../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\n",
    "CELL_MODEL = '../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\n",
    "\n",
    "segmentator = cellsegmentator.CellSegmentator(\n",
    "    NUC_MODEL,\n",
    "    CELL_MODEL,\n",
    "    scale_factor=0.25,\n",
    "    device='cuda',\n",
    "    padding=False,\n",
    "    multi_channel_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assigning bio style variables to images\n",
    "\n",
    "<code>mt = red_images # microtubules\n",
    "er = yellow_images # endoplasmic reticulum\n",
    "nu = blue_images # nucleus \n",
    "pr = green_images # [proteins]\n",
    "images = [mt, er, nu]</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(tez.Model):\n",
    "    '''Model class to facilitate transfer learning \n",
    "    from a resnet-18 model\n",
    "    '''\n",
    "    NUM_CLASSES = 19\n",
    "    DROPOUT_RATE = 0.1\n",
    "    \n",
    "    def __init__(self, resnet, train_df=None, valid_df=None, batch_size=16, train_aug=None, valid_aug=None, pretrained=True):\n",
    "        # Initialise pretrained net and final layers for cell classification\n",
    "        super().__init__()\n",
    "        self.convolutions = nn.Sequential(*(list(resnet.children())[0:-1]))\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "        self.dense = nn.Linear(512, self.NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "                \n",
    "    def forward(self, image, target=None):\n",
    "        batch_size = image.shape[0]\n",
    "        \n",
    "        # Extracts 512x1 feature vector from pretrained resnet18 conv layers\n",
    "        x = self.convolutions(image).reshape(batch_size, -1)\n",
    "        # Fully connected dense layer to 19 class output\n",
    "        output = self.dense(self.dropout(x))\n",
    "        # Sigmoid activations on output to infer class probabilities\n",
    "        output_probs = self.out(output)\n",
    "        \n",
    "        if target is not None:\n",
    "            loss = self.loss_fn(output_probs, target.to(torch.float32))  # why to float32???\n",
    "            metrics = self.monitor_metrics(output_probs, target)\n",
    "            return output_probs, loss, metrics\n",
    "        return output_probs, None, None\n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return opt\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "        )\n",
    "        return sch\n",
    "\n",
    "inf_aug = A.Compose([\n",
    "    A.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406), \n",
    "        std=(0.229, 0.224, 0.225), \n",
    "        max_pixel_value=1.0,\n",
    "        p=1.0\n",
    "    )\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(img, model, inf_aug):\n",
    "    ''' In: np.array (512, 512, 3) image\n",
    "        Out: np.array (1, 19) label-probs\n",
    "    '''\n",
    "    # Augment; re-shuffle channels; reshape; send to gpu\n",
    "    X = inf_aug(image=img)['image']\n",
    "    X = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "    X = torch.tensor(X, dtype=torch.float32).to('cuda')\n",
    "    X = X.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        out = model(X)[0]\n",
    "    return out.cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference(rgby_channel: tuple, model, inf_aug) -> tuple:\n",
    "    \"\"\"\n",
    "    Input: rgby_channel for cell\n",
    "    Pass: pass on model and augmentations for inference\n",
    "    Output: prediction from inference of model\n",
    "    \n",
    "    NB: This function currently randomly predicts each class\n",
    "    \"\"\"\n",
    "    # unpack rgby channel\n",
    "    r, g, b, y = rgby_channel\n",
    "    # stack img array\n",
    "    img = np.dstack((r, g, b))\n",
    "    # resize like in training\n",
    "    img = resize(img, (512, 512))\n",
    "    # get inference\n",
    "    pred = infer(img, model, inf_aug)\n",
    "    # ensure right shape\n",
    "    assert pred.shape[0]==1\n",
    "    assert pred.shape[1]==19\n",
    "    return(pred[0])\n",
    "\n",
    "\n",
    "def convert_sample_submission(path='/kaggle/input/hpa-single-cell-image-classification/sample_submission.csv')-> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Input: path to sample_submission.csv\n",
    "    Output: csv submission without PredictionString\n",
    "    \"\"\"\n",
    "    # read sample_submission csv\n",
    "    sample_submission = pd.read_csv(path)\n",
    "    # create new dataframe without prediction String\n",
    "    submission = sample_submission.drop(columns = ['PredictionString'])\n",
    "    return(submission)\n",
    "    \n",
    "    \n",
    "def read_image_array(ID, path='/kaggle/input/hpa-single-cell-image-classification/test/'):\n",
    "    \"\"\"\n",
    "    Input: ID and path to images\n",
    "    Output: np arrays for each channels\n",
    "    \"\"\"\n",
    "    r = imageio.imread(path+ID+'_red.png')\n",
    "    g = imageio.imread(path+ID+'_green.png')\n",
    "    b = imageio.imread(path+ID+'_blue.png')\n",
    "    y = imageio.imread(path+ID+'_yellow.png')\n",
    "    return r, g, b, y\n",
    "\n",
    "\n",
    "def segment(ref_channels: List[str], segmentator: CellSegmentator)-> np.ndarray:\n",
    "    \"\"\"\n",
    "    Input: reference channels for segementation class and segmentation class\n",
    "    Output: mask for image\n",
    "    \"\"\"\n",
    "    # Ref channels must be in order red, yellow, blue\n",
    "    input_ = [[i] for i in ref_channels]  # Segmentator only accepts list of lists input\n",
    "    nuc_segmentation = segmentator.pred_nuclei(input_[2])[0]\n",
    "    cell_segmentation = segmentator.pred_cells(input_)[0]\n",
    "    mask = label_cell(nuc_segmentation, cell_segmentation)[1]\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_rle_string(rgby_channel: tuple, binary_mask: np.ndarray, model, inf_aug)-> str:\n",
    "    \"\"\"\n",
    "    Input: cell rgby channels and binary mask for cell\n",
    "    Pass: pass on model and augmentations for inference\n",
    "    Output: prediction string for cell\n",
    "    \"\"\"\n",
    "    # get predictions\n",
    "    class_preds = get_inference(rgby_channel, model, inf_aug)\n",
    "    # add to prediction string\n",
    "    enc = encode_binary_mask(binary_mask)\n",
    "    # pred string\n",
    "    pred_string = ''\n",
    "    for jj, pred in enumerate(class_preds):\n",
    "        pred_string += str(jj)+' '+str(pred)+' '+enc+ ' '\n",
    "    return(pred_string)\n",
    "\n",
    "\n",
    "def extract_and_predict(channels: tuple, mask: np.ndarray, model, inf_aug) -> str:\n",
    "    \"\"\"\n",
    "    Input: whole image channels and mask for whole image\n",
    "    Pass: passing on model and augmentations for inference\n",
    "    Output: prediction string for whole image to be inputted to csv\n",
    "    \"\"\"\n",
    "    # master predicted_string\n",
    "    predicted_string = ''\n",
    "    for label in np.unique(mask):\n",
    "        # Get values from where image == label\n",
    "        if label == 0:\n",
    "            continue  # ignore background\n",
    "        temp_mask = mask.copy()\n",
    "        temp_mask[temp_mask != label] = 0\n",
    "        temp_mask[temp_mask == label] = 1\n",
    "        # Get temp mask bounding box coords\n",
    "        idxs = np.asarray(temp_mask == 1).nonzero()\n",
    "        y_min, y_max = idxs[0].min(), idxs[0].max()\n",
    "        x_min, x_max = idxs[1].min(), idxs[1].max()\n",
    "\n",
    "        # tuple of all channels to be classified\n",
    "        rgby_channel_list = list()\n",
    "        for channel in channels:\n",
    "            # Zero pad and square off\n",
    "            single_cell = temp_mask * channel\n",
    "            single_cell = single_cell[y_min:(y_max + 1), x_min:(x_max + 1)]\n",
    "            # append channel to list\n",
    "            rgby_channel_list.append(single_cell)\n",
    "        # return prediction string to append\n",
    "        predicted_string += get_rle_string(tuple(rgby_channel_list), np.array(temp_mask, dtype=bool),\n",
    "                                           model, inf_aug)\n",
    "    return(predicted_string)\n",
    "\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray)-> str:\n",
    "    \"\"\"\n",
    "    Input: binary mask\n",
    "    Output: encoded rle mask, decoded into ascii text\n",
    "    \"\"\"\n",
    "\n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(\n",
    "           \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "           mask.dtype)\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(\n",
    "           \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "           mask.shape)\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str.decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = convert_sample_submission()\n",
    "# load pretrained model\n",
    "resnet_model = resnet18(pretrained=False)\n",
    "resnet_model.load_state_dict(torch.load(RESNET_PATH))\n",
    "# define model class\n",
    "model = ResNet18(resnet_model)\n",
    "# load weights\n",
    "model.load(MODEL_PATH)\n",
    "# augmentations\n",
    "inf_aug = A.Compose([\n",
    "A.Normalize(\n",
    "    mean=MEAN_CHANNEL_VALUES, \n",
    "    std=CHANNEL_STD_DEV, \n",
    "    max_pixel_value=1.0,\n",
    "    p=1.0\n",
    "    )\n",
    "])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################################################\n",
      "Segmenting image 0040581b-f1f2-4fbe-b043-b6bfea5404bb\n",
      "#####################################################\n",
      "Segmenting image 004a270d-34a2-4d60-bbe4-365fca868193\n",
      "#####################################################\n",
      "Segmenting image 00537262-883c-4b37-a3a1-a4931b6faea5\n",
      "#####################################################\n",
      "Segmenting image 00c9a1c9-2f06-476f-8b0d-6d01032874a2\n",
      "#####################################################\n",
      "Segmenting image 0173029a-161d-40ef-af28-2342915b22fb\n",
      "#####################################################\n",
      "Segmenting image 01a14326-67b8-43b0-ac7a-ba6dfb3c38ad\n",
      "#####################################################\n",
      "Segmenting image 020a29cf-2c24-478b-8603-c22a90dc3e31\n",
      "#####################################################\n",
      "Segmenting image 02425037-3048-4ff3-9c0a-e9fc2d033e32\n",
      "#####################################################\n",
      "Segmenting image 02531b54-078d-4a33-9c9c-0632b58c0a9a\n",
      "#####################################################\n",
      "Segmenting image 025f04f1-6c68-4606-b34b-047738dd4804\n",
      "#####################################################\n",
      "Segmenting image 02861579-97fb-4482-a613-356e0bf5d090\n",
      "#####################################################\n",
      "Segmenting image 02b3c5aa-d70c-49d1-b3e5-3f5cc10375ca\n",
      "#####################################################\n",
      "Segmenting image 02f9ee97-bf2e-4d9d-bdfd-b903ec2e79c0\n",
      "#####################################################\n",
      "Segmenting image 036cd088-40fc-4ab0-a131-a6c02f02440a\n",
      "#####################################################\n",
      "Segmenting image 03aa8433-b927-4495-a6e2-d03cdc17d76b\n",
      "#####################################################\n",
      "Segmenting image 04c1b106-a5a4-419d-96c6-2750ebe2b50d\n"
     ]
    }
   ],
   "source": [
    "# Iterate over test dataframce\n",
    "for image in df.itertuples():\n",
    "    print('#####################################################')\n",
    "    print('Segmenting image {}'.format(image.ID))\n",
    "    try:    \n",
    "        # segment and extract\n",
    "        r, g, b, y = read_image_array(image.ID)\n",
    "        # assign ref channels\n",
    "        ref_channels = [r, y, b]\n",
    "        # get mask\n",
    "        mask = segment(ref_channels, segmentator)\n",
    "        # get predicted string\n",
    "        df.at[image.Index, 'PredictedString'] = extract_and_predict((r, g, b, y), \n",
    "                                                                    mask,\n",
    "                                                                    model,\n",
    "                                                                    inf_aug)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "#     # plot \n",
    "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#     ax.imshow(np.dstack((r, g, b)))\n",
    "#     ax.imshow(mask, alpha=0.3)\n",
    "#     plt.title('Image Example: {}'.format(ID))\n",
    "#     plt.show()\n",
    "#     print(predicted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many images were unsucessful\n",
    "df[df.PredictedString.isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission cv\n",
    "df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
