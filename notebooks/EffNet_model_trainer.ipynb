{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "radio-potato",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rocky-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = ['red', 'green', 'blue', 'yellow']\n",
    "TRAIN_CSV = 'D:/HPA_comp/single_cells/train_folds_big.csv'\n",
    "IMG_DIR = 'D:/HPA_comp/single_cells'\n",
    "MEAN_CHANNEL_VALUES = [0.485, 0.456, 0.406]\n",
    "CHANNEL_STD_DEV = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "novel-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, average_precision_score\n",
    "from statistics import mean\n",
    "\n",
    "def skl_mAP(y_preds, y_targets):\n",
    "    'Return sklearn mean average precision across valid labels'\n",
    "    ap_rec = []\n",
    "    # Calc avg precision score one label at a time\n",
    "    for lab in range(y_targets.shape[1]):\n",
    "        y_pred = y_preds[:, lab]\n",
    "        y_target = y_targets[:, lab]\n",
    "        # If no targets present, skip label to avoid /0 runtime warning\n",
    "        if y_target.sum() == 0:\n",
    "            continue\n",
    "        ap = average_precision_score(y_target, y_pred)\n",
    "        ap_rec.append(ap)\n",
    "    if len(ap_rec) == 0:\n",
    "        return np.nan\n",
    "    mean_AP = mean(ap_rec)\n",
    "    return mean_AP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-texas",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tender-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "\n",
    "class CellDataset(object):\n",
    "    '''Dataset class to fetch HPA cell-level images\n",
    "    and corresponding weak labels\n",
    "    '''\n",
    "    def __init__(self, images, targets, img_root, augmentations=None):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.img_root = img_root\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.images[idx] \n",
    "        img_channels = self._fetch_channels(img_id)\n",
    "        img = self._channels_2_array(img_channels)\n",
    "        img = resize(img, (260, 260))  # Always resize cell images for collate function\n",
    "        # If augmentation pipeline provided, apply augmentations\n",
    "        if self.augmentations:\n",
    "            img = self.augmentations(image=img)['image']\n",
    "        # Adjust to channel first indexing for pytorch (speed reasons)\n",
    "        features = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "        target = self.targets[idx]  # Grab target vector\n",
    "        \n",
    "        return {'image': torch.tensor(features),\n",
    "                'target': torch.tensor(target)\n",
    "                }\n",
    "    \n",
    "    def _fetch_channels(self, img_id: str, channel_names=CHANNELS):\n",
    "        'Return absolute path of segmentation channels of a given image id'\n",
    "        base = os.path.join(self.img_root, img_id)\n",
    "        return [base + '_' + i  + '.png' for i in channel_names]\n",
    "                                         \n",
    "    def _channels_2_array(self, img_channels):\n",
    "        'Return 3D array of pixel values of input image channels'\n",
    "        r = imageio.imread(img_channels[0])\n",
    "        g = imageio.imread(img_channels[1])\n",
    "        b = imageio.imread(img_channels[2])\n",
    "        pixel_arr = np.dstack((r, g, b))\n",
    "        return pixel_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-grill",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjustable-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import tez\n",
    "\n",
    "#from custom_metrics import skl_mAP\n",
    "\n",
    "\n",
    "class EfficientNetB2(tez.Model):\n",
    "    '''Model class to facilitate transfer learning \n",
    "    from a resnet-18 model\n",
    "    '''\n",
    "    NUM_CLASSES = 19\n",
    "    DROPOUT_RATE = 0.1\n",
    "    IMG_DIR = 'D:/HPA_comp/single_cells'\n",
    "    \n",
    "    def __init__(self, train_df, valid_df, batch_size, train_aug=None, valid_aug=None, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Initialise pretrained net and sub-in final layers for cell classification\n",
    "        self.effnet = self.load_effnet(pretrained)\n",
    "        self.effnet._fc = nn.Linear(1408, self.NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.step_scheduler_after = \"epoch\"\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "        \n",
    "        # Below should probably be in tez.Model super class but is a quick hack around\n",
    "        self.train_loader = self.gen_dataloader(train_df, batch_size, shuffle=True, aug=train_aug)\n",
    "        self.valid_loader = self.gen_dataloader(valid_df, batch_size, shuffle=False, aug=valid_aug)\n",
    "        \n",
    "    def forward(self, image, target=None):\n",
    "        # Forward prob on effnet model w/ sigmoid activations final layer\n",
    "        x = self.effnet(image)\n",
    "        output = self.out(x)\n",
    "        \n",
    "        if target is not None:\n",
    "            loss = self.loss_fn(output, target.to(torch.float32))  # why to float32???\n",
    "            metrics = self.monitor_metrics(output, target)\n",
    "            return output, loss, metrics\n",
    "        return output, None, None\n",
    "    \n",
    "    def monitor_metrics(self, outputs, targets):\n",
    "        if targets is None:\n",
    "            return {}\n",
    "        targets = targets.cpu().detach().numpy()\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        # Calculate batch metrics\n",
    "        mean_AP = skl_mAP(outputs, targets)\n",
    "        return {'mAP': mean_AP}\n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return opt\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "        )\n",
    "        return sch\n",
    "    \n",
    "    def gen_dataloader(self, df, bs, shuffle, aug=None):\n",
    "        'Return pytorch dataloader generated from cell image dataframe'\n",
    "        # Extract images and targets as numpy arrays from dataframe tranche\n",
    "        def extract_as_array(str_):\n",
    "            list_ = str_.strip('][').split(', ')\n",
    "            return np.array([int(i) for i in list_])\n",
    "        images = df['cell_id'].values\n",
    "        targets = df['Label'].apply(extract_as_array).values\n",
    "        # Init custom dataset class and pass to pytorch\n",
    "        dataset = CellDataset(images, targets, self.IMG_DIR, aug)\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=shuffle)\n",
    "    \n",
    "    def load_effnet(self, pretrained):\n",
    "        if pretrained == True:\n",
    "            effnet = EfficientNet.from_pretrained(\"efficientnet-b2\")\n",
    "        else:\n",
    "            effnet = EfficientNet.from_name(\"efficientnet-b2\")\n",
    "        return effnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-forth",
   "metadata": {},
   "source": [
    "## if __name__ == '__main__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "meaning-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# Image augmentation stack \n",
    "train_aug = A.Compose([\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(\n",
    "        mean=MEAN_CHANNEL_VALUES,\n",
    "        std=CHANNEL_STD_DEV,\n",
    "        max_pixel_value=1.0,\n",
    "        p=1.0\n",
    "    )\n",
    "])\n",
    "\n",
    "valid_aug = A.Compose([\n",
    "    A.Normalize(\n",
    "        mean=MEAN_CHANNEL_VALUES,\n",
    "        std=CHANNEL_STD_DEV,\n",
    "        max_pixel_value=1.0,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "following-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 4.08 GiB already allocated; 11.73 MiB free; 4.15 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-416b60fd9bfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Model training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# dataset inits are overriden in the model class above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mvalid_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# otherwise tez breaks for me when it tries to do this itself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\tez\\model\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_dataset, valid_dataset, train_sampler, valid_sampler, device, epochs, train_bs, valid_bs, n_jobs, callbacks, fp16, train_collate_fn, valid_collate_fn)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_START\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN_EPOCH_START\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN_EPOCH_END\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\tez\\model\\model.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, data_loader)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN_STEP_START\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menums\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN_STEP_END\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\tez\\model\\model.py\u001b[0m in \u001b[0;36mtrain_one_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_one_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\tez\\model\\model.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    150\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d67085adc9d6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, image, target)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Forward prob on effnet model w/ sigmoid activations final layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\efficientnet_pytorch\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m    310\u001b[0m         \u001b[1;31m# Convolution layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[1;31m# Pooling and final linear layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_avg_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\efficientnet_pytorch\\model.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# scale drop connect_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[1;31m# Head\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\efficientnet_pytorch\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_block_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_ratio\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expand_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cell\\lib\\site-packages\\efficientnet_pytorch\\utils.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 6.00 GiB total capacity; 4.08 GiB already allocated; 11.73 MiB free; 4.15 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Select training folds from csv\n",
    "dfx = pd.read_csv(TRAIN_CSV, index_col=0)   #.iloc[:100, :]\n",
    "FOLD = 0\n",
    "\n",
    "df_train = dfx[dfx['fold'] != FOLD].reset_index(drop=True)\n",
    "df_valid = dfx[dfx['fold'] == FOLD].reset_index(drop=True)\n",
    "\n",
    "# Init model\n",
    "model = EfficientNetB2(\n",
    "     df_train,\n",
    "     df_valid, \n",
    "     batch_size=16, \n",
    "     train_aug=train_aug, \n",
    "     valid_aug=valid_aug, \n",
    "     pretrained=True\n",
    ")\n",
    "\n",
    "# Load model from checkpoint\n",
    "#model_path = '../models/model_checkpoint_effnet.bin'\n",
    "#model.load(model_path)\n",
    "\n",
    "# Early stopping\n",
    "from tez.callbacks import EarlyStopping\n",
    "es = EarlyStopping(\n",
    "    monitor='valid_loss',\n",
    "    model_path='../models/effnetb2_checkpoint.bin',\n",
    "    patience=3,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Model training\n",
    "model.fit(\n",
    "    train_dataset=None,  # dataset inits are overriden in the model class above\n",
    "    valid_dataset=None,  # otherwise tez breaks for me when it tries to do this itself\n",
    "    train_bs=16,\n",
    "    device='cuda',\n",
    "    callbacks=[es],\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Save model (with optimizer and scheduler for future usage)\n",
    "model.save('../models/trained_effnetb2.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
