{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "female-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "MEAN_CHANNEL_VALUES = (0.07730, 0.05958, 0.07135)  # RGB\n",
    "CHANNEL_STD_DEV = (0.12032, 0.08593, 0.14364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unexpected-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "import tez\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "class ResNet18(tez.Model):\n",
    "    '''Model class to facilitate transfer learning \n",
    "    from a resnet-18 model\n",
    "    '''\n",
    "    NUM_CLASSES = 19\n",
    "    DROPOUT_RATE = 0.1\n",
    "    IMG_DIR = 'D:/HPA_comp/single_cells'\n",
    "    \n",
    "    def __init__(self, train_df=None, valid_df=None, batch_size=16, train_aug=None, valid_aug=None, pretrained=True):\n",
    "        # Initialise pretrained net and final layers for cell classification\n",
    "        super().__init__()\n",
    "        self.convolutions = nn.Sequential(*(list(resnet18(pretrained).children())[0:-1]))\n",
    "        self.dropout = nn.Dropout(self.DROPOUT_RATE)\n",
    "        self.dense = nn.Linear(512, self.NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "                \n",
    "    def forward(self, image, target=None):\n",
    "        batch_size = image.shape[0]\n",
    "        \n",
    "        # Extracts 512x1 feature vector from pretrained resnet18 conv layers\n",
    "        x = self.convolutions(image).reshape(batch_size, -1)\n",
    "        # Fully connected dense layer to 19 class output\n",
    "        output = self.dense(self.dropout(x))\n",
    "        # Sigmoid activations on output to infer class probabilities\n",
    "        output_probs = self.out(output)\n",
    "        \n",
    "        if target is not None:\n",
    "            loss = self.loss_fn(output_probs, target.to(torch.float32))  # why to float32???\n",
    "            metrics = self.monitor_metrics(output_probs, target)\n",
    "            return output_probs, loss, metrics\n",
    "        return output_probs, None, None\n",
    "    \n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return opt\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n",
    "        )\n",
    "        return sch\n",
    "\n",
    "inf_aug = A.Compose([\n",
    "    A.Normalize(\n",
    "        mean=MEAN_CHANNEL_VALUES,\n",
    "        std=CHANNEL_STD_DEV,\n",
    "        max_pixel_value=1.0,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "molecular-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(img, model, inf_aug):\n",
    "    'In: np.array (244, 244, 3); out: np.array (1, 19)'\n",
    "    # Augment; re-shuffle channels; reshape; send to gpu\n",
    "    X = inf_aug(image=img)['image']\n",
    "    X = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "    X = X.reshape((1, 3, 224, 224))\n",
    "    X = torch.tensor(X, dtype=torch.float32).to('cuda')\n",
    "    with torch.no_grad():\n",
    "        out = model(X)[0]\n",
    "    return out.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opened-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18()\n",
    "model.load('../models/test_trained_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advised-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0226492e-01, 1.2569706e-02, 4.9887609e-02, 1.2750092e-02,\n",
       "        1.2971192e-02, 2.3765745e-02, 1.9739717e-02, 1.9892044e-02,\n",
       "        1.4863893e-02, 1.0636472e-02, 2.0367175e-03, 3.3339605e-04,\n",
       "        3.7639823e-02, 7.0945047e-02, 3.2744169e-02, 4.9520819e-03,\n",
       "        1.7193443e-01, 5.3259977e-03, 6.2999275e-04]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.zeros([224, 224, 3], dtype='float32')\n",
    "\n",
    "infer(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
