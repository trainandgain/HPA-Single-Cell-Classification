{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cab3826",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "For our problem we have the output from the model as:\n",
    "\n",
    "$[N, C]$\n",
    "\n",
    "And our labels are one hot encoding are the same:\n",
    "\n",
    "$[N, C]$ \n",
    "\n",
    "where N is the number of samples, C is either {1, 0}.\n",
    "\n",
    "In PyTorch torch.nn.BCELoss() is [Binary Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html):\n",
    "\n",
    "Which expects the input:\n",
    "\n",
    "***\n",
    "\n",
    "Input: (N, *)(N,∗) where *∗ means, any number of additional dimensions\n",
    "\n",
    "Target: (N, *)(N,∗) , same shape as the input\n",
    "\n",
    "Output: scalar. If reduction is 'none', then (N, *)(N,∗) , same shape as input.\n",
    "\n",
    "***\n",
    "\n",
    "We want to apply the sigmoid function to the inputs to ensure they are in the 0 -> 1 range.\n",
    "\n",
    "We could also just use nn.BCEWithLogitsLoss() which includes this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7db41d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0817, -1.6292,  0.2751])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fake ouputs from model\n",
    "outputs = torch.randn(3)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae8def2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01f2451a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.empty(3).random_(2)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1cce2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10c9f5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4657)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(m(outputs), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9c1092d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4657)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instead of using the sigmoid \n",
    "# use sigmoid function\n",
    "loss2 = nn.BCEWithLogitsLoss()\n",
    "loss2(outputs, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651fd88",
   "metadata": {},
   "source": [
    "[A good example](https://jbencook.com/cross-entropy-loss-in-pytorch/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
