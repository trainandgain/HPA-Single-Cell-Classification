{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impaired-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new skl mAP with handling for missing targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "egyptian-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, average_precision_score\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "addressed-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prec_rec(y_pred_, y_target, thresh):\n",
    "    'Return precision and recall in tuple'\n",
    "    y_pred = y_pred_.copy()\n",
    "    # Convert to binary predictions\n",
    "    super_idxs = y_pred >= thresh\n",
    "    y_pred[super_idxs] = 1\n",
    "    sub_idxs = y_pred < thresh\n",
    "    y_pred[sub_idxs] = 0\n",
    "    \n",
    "    tp = (y_pred.T @ y_target).item()\n",
    "    fp = sum((y_pred - y_target) > 0).item()\n",
    "    fn = sum((y_pred - y_target) < 0).item()\n",
    "    \n",
    "    if (tp + fp) == 0:\n",
    "        precision = None\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    \n",
    "    if (tp + fn) == 0:\n",
    "        recall = None\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "def mAP(y_preds, y_targets, n_iters=10):\n",
    "    'Return mean average precision across labels'\n",
    "    ap_rec = []\n",
    "    # Calc avg precision score one label at a time\n",
    "    for lab in range(y_targets.shape[1]):\n",
    "        y_pred = y_preds[:, lab]\n",
    "        y_target = y_targets[:, lab]\n",
    "        \n",
    "        prec_rec = []\n",
    "        for thresh in np.linspace(0, 0.9, n_iters):\n",
    "            prec, rec = calc_prec_rec(y_pred, y_target, thresh)\n",
    "            if prec is None or rec is None:\n",
    "                continue\n",
    "            prec_rec.append([prec, rec])\n",
    "        if len(prec_rec) <= 1:\n",
    "            continue\n",
    "        # Extract precision recall for given thresholds and estimate auc\n",
    "        prec_rec = np.array(prec_rec)\n",
    "        prec, rec = prec_rec[:, 0], prec_rec[:, 1]\n",
    "        print(rec)\n",
    "        ap = auc(rec, prec)\n",
    "        ap_rec.append(ap)\n",
    "    if len(ap_rec) == 0:\n",
    "        return np.nan\n",
    "    mean_AP = mean(ap_rec)\n",
    "    return mean_AP\n",
    "\n",
    "def skl_mAP(y_preds, y_targets, n_iters=10):\n",
    "    'Return mean average precision across labels'\n",
    "    ap_rec = []\n",
    "    # Calc avg precision score one label at a time\n",
    "    for lab in range(y_targets.shape[1]):\n",
    "        y_pred = y_preds[:, lab]\n",
    "        y_target = y_targets[:, lab]\n",
    "        # If no targets present, skip label to avoid /0 runtime warning\n",
    "        if y_target.sum() == 0:\n",
    "            continue\n",
    "        ap = average_precision_score(y_target, y_pred)\n",
    "        ap_rec.append(ap)\n",
    "    if len(ap_rec) == 0:\n",
    "        return np.nan\n",
    "    mean_AP = mean(ap_rec)\n",
    "    return mean_AP\n",
    "\n",
    "def mF1():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "moral-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "y_preds = np.random.rand(16, 19)\n",
    "y_targets = np.zeros(shape=(16, 19))\n",
    "\n",
    "y_targets[3, 1] = 1\n",
    "#prec, rec = calc_prec_rec(y_pred, y_target, 0.5)\n",
    "#prec_rec.append([prec, rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "integrated-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP(y_preds, y_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorporated-circulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_mAP(y_preds, y_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
