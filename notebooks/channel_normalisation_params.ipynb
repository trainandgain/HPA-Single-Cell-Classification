{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepted-glenn",
   "metadata": {},
   "source": [
    "### Finding RGB channel normalisation params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "explicit-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pixel data\n",
    "# Random sample\n",
    "# Extract and print channel means and std_dev \n",
    "# (across images, we need avg std dev within a given cell image across images, \n",
    "# avg channel value in image across images)\n",
    "\n",
    "# We always normalise last, for obvious reasons, if you're using saturation \n",
    "# or any sort of colour augmentation normalisation gets fucked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "forty-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "\n",
    "CHANNELS = ['red', 'green', 'blue', 'yellow']\n",
    "TRAIN_CSV = 'D:/HPA_comp/single_cells/train.csv'\n",
    "IMG_DIR = 'D:/HPA_comp/single_cells'\n",
    "\n",
    "class CellDataset(object):\n",
    "    '''Dataset class to fetch HPA cell-level images\n",
    "    and corresponding weak labels\n",
    "    '''\n",
    "    def __init__(self, images, targets, img_root, augmentations=None):\n",
    "        self.images = images\n",
    "        self.targets = targets\n",
    "        self.img_root = img_root\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.images[idx] \n",
    "        img_channels = self._fetch_channels(img_id)\n",
    "        img = self._channels_2_array(img_channels)\n",
    "        img = resize(img, (224, 224))  # Always resize cell images for collate function\n",
    "        # If augmentation pipeline provided, apply augmentations\n",
    "        if self.augmentations:\n",
    "            img = self.augmentations(image=img)['image']\n",
    "        # Adjust to channel first indexing for pytorch (speed reasons)\n",
    "        features = np.transpose(img, (2, 0, 1)).astype(np.float32)\n",
    "        target = self.targets[idx]  # Grab target vector\n",
    "        \n",
    "        return {'image': torch.tensor(features),\n",
    "                'target': torch.tensor(target)\n",
    "                }\n",
    "    \n",
    "    def _fetch_channels(self, img_id: str, channel_names=CHANNELS):\n",
    "        'Return absolute path of segmentation channels of a given image id'\n",
    "        base = os.path.join(self.img_root, img_id)\n",
    "        return [base + '_' + i  + '.png' for i in channel_names]\n",
    "                                         \n",
    "    def _channels_2_array(self, img_channels):\n",
    "        'Return 3D array of pixel values of input image channels'\n",
    "        # Init and reshape single channel array so we can concat other channels\n",
    "        channel_1 = np.array(Image.open(img_channels[0]))\n",
    "        shape = channel_1.shape + (1,)  \n",
    "        pixel_arr = channel_1.reshape(shape)\n",
    "        # Lay out 4 channels in 3D array for model input\n",
    "        for channel in img_channels[1:3]:\n",
    "            channel_values = np.array(Image.open(channel)).reshape(shape)\n",
    "            pixel_arr = np.concatenate([pixel_arr, channel_values], axis=2)\n",
    "        return pixel_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataloader(df, img_dir, bs, shuffle, aug=None):\n",
    "        'Return pytorch dataloader generated from cell image dataframe'\n",
    "        # Extract images and targets as numpy arrays from dataframe tranche\n",
    "        def extract_as_array(str_):\n",
    "            list_ = str_.strip('][').split(', ')\n",
    "            return np.array([int(i) for i in list_])\n",
    "        images = df['cell_id'].values\n",
    "        targets = df['Label'].apply(extract_as_array).values\n",
    "        # Init custom dataset class and pass to pytorch\n",
    "        dataset = CellDataset(images, targets, img_dir, aug)\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "purple-roberts",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grab_pixel_aggs(dataloader, sample_size):\n",
    "    'Return dataframe of image channel means and standard deviations'\n",
    "    aggs_df = pd.DataFrame()\n",
    "    \n",
    "    for count, sample in enumerate(dataloader):\n",
    "        image_tensor = sample['image']  # indexed by (C, H, W)\n",
    "        aggs = {}\n",
    "        # Grab cell image channel aggregates\n",
    "        channels = ['red', 'green', 'blue']\n",
    "        for idx, channel_name in enumerate(channels):\n",
    "            channel = image_tensor[0, idx, :, :]\n",
    "            min_value = channel.min().item()\n",
    "            max_value = channel.max().item()\n",
    "            mean = channel.mean().item()\n",
    "            std = channel.std().item()\n",
    "            aggs[channel_name + '_max'] = max_value\n",
    "            aggs[channel_name + '_min'] = min_value\n",
    "            aggs[channel_name + '_mean'] = mean\n",
    "            aggs[channel_name + '_std'] = std\n",
    "        aggs_df = aggs_df.append(aggs, ignore_index=True)\n",
    "        if count >= sample_size:\n",
    "            break\n",
    "    return aggs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "discrete-temperature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue_max</th>\n",
       "      <th>blue_mean</th>\n",
       "      <th>blue_min</th>\n",
       "      <th>blue_std</th>\n",
       "      <th>green_max</th>\n",
       "      <th>green_mean</th>\n",
       "      <th>green_min</th>\n",
       "      <th>green_std</th>\n",
       "      <th>red_max</th>\n",
       "      <th>red_mean</th>\n",
       "      <th>red_min</th>\n",
       "      <th>red_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.017685e-07</td>\n",
       "      <td>3.407981e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.366696e-08</td>\n",
       "      <td>9.773566e-08</td>\n",
       "      <td>3.075792e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>6.779227e-09</td>\n",
       "      <td>1.180451e-07</td>\n",
       "      <td>1.170326e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.965228e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.177885e-08</td>\n",
       "      <td>3.485120e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>8.719230e-09</td>\n",
       "      <td>4.949080e-08</td>\n",
       "      <td>8.663201e-10</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.782882e-09</td>\n",
       "      <td>8.466778e-08</td>\n",
       "      <td>3.266735e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>6.834032e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.433873e-09</td>\n",
       "      <td>1.190104e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.307362e-09</td>\n",
       "      <td>2.844981e-08</td>\n",
       "      <td>2.374449e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>3.033945e-09</td>\n",
       "      <td>4.196163e-08</td>\n",
       "      <td>4.602498e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>5.035229e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.174547e-07</td>\n",
       "      <td>1.950569e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>2.694077e-08</td>\n",
       "      <td>1.188808e-07</td>\n",
       "      <td>1.770982e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.975254e-08</td>\n",
       "      <td>1.112879e-07</td>\n",
       "      <td>8.423744e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.386540e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.171887e-07</td>\n",
       "      <td>5.739611e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.876061e-08</td>\n",
       "      <td>1.175805e-07</td>\n",
       "      <td>2.035665e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>2.426175e-08</td>\n",
       "      <td>1.097973e-07</td>\n",
       "      <td>1.481661e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.816342e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.459000e-08</td>\n",
       "      <td>3.574714e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>7.023750e-09</td>\n",
       "      <td>1.154131e-07</td>\n",
       "      <td>1.183415e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.235096e-08</td>\n",
       "      <td>1.028830e-07</td>\n",
       "      <td>9.569090e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.264736e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.369000e-08</td>\n",
       "      <td>1.299507e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.657644e-08</td>\n",
       "      <td>1.189765e-07</td>\n",
       "      <td>1.533726e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.646218e-08</td>\n",
       "      <td>1.168788e-07</td>\n",
       "      <td>1.974368e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>2.007542e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.180264e-07</td>\n",
       "      <td>8.287586e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>2.125565e-08</td>\n",
       "      <td>1.185108e-07</td>\n",
       "      <td>1.016177e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>2.078091e-08</td>\n",
       "      <td>1.180309e-07</td>\n",
       "      <td>9.790337e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.650134e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.368039e-08</td>\n",
       "      <td>4.320826e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.467616e-08</td>\n",
       "      <td>1.131844e-07</td>\n",
       "      <td>1.448359e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>5.573459e-09</td>\n",
       "      <td>1.189765e-07</td>\n",
       "      <td>1.082976e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.585119e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.101278e-07</td>\n",
       "      <td>7.547926e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.769076e-08</td>\n",
       "      <td>8.495734e-08</td>\n",
       "      <td>3.065560e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>4.675860e-09</td>\n",
       "      <td>1.159016e-07</td>\n",
       "      <td>9.108168e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>1.460226e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.741700e-08</td>\n",
       "      <td>3.433629e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>4.701832e-09</td>\n",
       "      <td>1.185108e-07</td>\n",
       "      <td>6.886089e-09</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>9.668859e-09</td>\n",
       "      <td>1.185108e-07</td>\n",
       "      <td>3.292232e-08</td>\n",
       "      <td>2.328306e-10</td>\n",
       "      <td>3.677217e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        blue_max     blue_mean      blue_min      blue_std     green_max  \\\n",
       "0   1.017685e-07  3.407981e-09  2.328306e-10  1.366696e-08  9.773566e-08   \n",
       "1   5.177885e-08  3.485120e-09  2.328306e-10  8.719230e-09  4.949080e-08   \n",
       "2   9.433873e-09  1.190104e-09  2.328306e-10  1.307362e-09  2.844981e-08   \n",
       "3   1.174547e-07  1.950569e-08  2.328306e-10  2.694077e-08  1.188808e-07   \n",
       "4   1.171887e-07  5.739611e-09  2.328306e-10  1.876061e-08  1.175805e-07   \n",
       "5   4.459000e-08  3.574714e-09  2.328306e-10  7.023750e-09  1.154131e-07   \n",
       "6   7.369000e-08  1.299507e-08  2.328306e-10  1.657644e-08  1.189765e-07   \n",
       "7   1.180264e-07  8.287586e-09  2.328306e-10  2.125565e-08  1.185108e-07   \n",
       "8   9.368039e-08  4.320826e-09  2.328306e-10  1.467616e-08  1.131844e-07   \n",
       "9   1.101278e-07  7.547926e-09  2.328306e-10  1.769076e-08  8.495734e-08   \n",
       "10  2.741700e-08  3.433629e-09  2.328306e-10  4.701832e-09  1.185108e-07   \n",
       "\n",
       "      green_mean     green_min     green_std       red_max      red_mean  \\\n",
       "0   3.075792e-09  2.328306e-10  6.779227e-09  1.180451e-07  1.170326e-08   \n",
       "1   8.663201e-10  2.328306e-10  1.782882e-09  8.466778e-08  3.266735e-09   \n",
       "2   2.374449e-09  2.328306e-10  3.033945e-09  4.196163e-08  4.602498e-09   \n",
       "3   1.770982e-08  2.328306e-10  1.975254e-08  1.112879e-07  8.423744e-09   \n",
       "4   2.035665e-08  2.328306e-10  2.426175e-08  1.097973e-07  1.481661e-08   \n",
       "5   1.183415e-08  2.328306e-10  1.235096e-08  1.028830e-07  9.569090e-09   \n",
       "6   1.533726e-08  2.328306e-10  1.646218e-08  1.168788e-07  1.974368e-08   \n",
       "7   1.016177e-08  2.328306e-10  2.078091e-08  1.180309e-07  9.790337e-09   \n",
       "8   1.448359e-09  2.328306e-10  5.573459e-09  1.189765e-07  1.082976e-08   \n",
       "9   3.065560e-09  2.328306e-10  4.675860e-09  1.159016e-07  9.108168e-09   \n",
       "10  6.886089e-09  2.328306e-10  9.668859e-09  1.185108e-07  3.292232e-08   \n",
       "\n",
       "         red_min       red_std  \n",
       "0   2.328306e-10  1.965228e-08  \n",
       "1   2.328306e-10  6.834032e-09  \n",
       "2   2.328306e-10  5.035229e-09  \n",
       "3   2.328306e-10  1.386540e-08  \n",
       "4   2.328306e-10  1.816342e-08  \n",
       "5   2.328306e-10  1.264736e-08  \n",
       "6   2.328306e-10  2.007542e-08  \n",
       "7   2.328306e-10  1.650134e-08  \n",
       "8   2.328306e-10  1.585119e-08  \n",
       "9   2.328306e-10  1.460226e-08  \n",
       "10  2.328306e-10  3.677217e-08  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_CSV, index_col=0)\n",
    "loader = gen_dataloader(df, img_dir=IMG_DIR, bs=1, shuffle=True, aug=None)\n",
    "aggs_df = grab_pixel_aggs(loader, sample_size=1000)\n",
    "aggs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "perfect-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scale magic numbers\n",
    "PIL_min = 2.3283e-10\n",
    "PIL_max = 1.189765e-07\n",
    "new_min = 0\n",
    "new_max = 255\n",
    "PIL_range = (PIL_max - PIL_min)  \n",
    "new_range = (new_max - new_min)\n",
    "\n",
    "rescale = lambda value: int((((value - PIL_min) * new_range) / PIL_range) + new_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-border",
   "metadata": {},
   "source": [
    "### Grab example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "documentary-prevention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.5243e-09, 7.8435e-09, 8.2695e-09,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.5386e-08, 2.7572e-08, 3.1816e-08,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.7025e-08, 2.6268e-08, 2.8277e-08,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          ...,\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 1.0626e-08,\n",
       "           1.5309e-08, 1.8186e-08],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           3.4990e-10, 6.3911e-10],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10]],\n",
       "\n",
       "         [[9.7992e-10, 3.4098e-09, 6.0179e-09,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [1.0175e-08, 1.0810e-08, 1.8552e-08,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [1.4866e-08, 1.4369e-08, 8.7250e-09,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          ...,\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 3.7149e-09,\n",
       "           5.8400e-09, 5.3594e-09],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10]],\n",
       "\n",
       "         [[2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          ...,\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10],\n",
       "          [2.3283e-10, 2.3283e-10, 2.3283e-10,  ..., 2.3283e-10,\n",
       "           2.3283e-10, 2.3283e-10]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in loader:\n",
    "    img = i['image']\n",
    "    break\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-essex",
   "metadata": {},
   "source": [
    "### Convert back to integer pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "conceptual-leisure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7., 16., 17.,  ...,  0.,  0.,  0.],\n",
       "        [54., 58., 67.,  ...,  0.,  0.,  0.],\n",
       "        [57., 55., 60.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ..., 22., 32., 38.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0, 0, :, :].apply_(rescale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-communist",
   "metadata": {},
   "source": [
    "### Check scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "hearing-healthcare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total non-integer values (account for rounding error)\n",
    "((img % 1) >= 1e-6).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "judicial-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "254.0\n"
     ]
    }
   ],
   "source": [
    "# Rescaled pixel range\n",
    "print(img.min().item())\n",
    "print(img.max().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
