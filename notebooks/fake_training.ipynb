{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cab3826",
   "metadata": {},
   "source": [
    "# Fake Training\n",
    "\n",
    "For our problem we have the output from the model as:\n",
    "\n",
    "$[N, C]$\n",
    "\n",
    "And our labels are one hot encoding are the same:\n",
    "\n",
    "$[N, C]$ \n",
    "\n",
    "where N is the number of samples, C is either {1, 0}.\n",
    "\n",
    "In PyTorch torch.nn.BCELoss() is [Binary Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html):\n",
    "\n",
    "Which expects the input:\n",
    "\n",
    "***\n",
    "\n",
    "Input: (N, *)(N,∗) where *∗ means, any number of additional dimensions\n",
    "\n",
    "Target: (N, *)(N,∗) , same shape as the input\n",
    "\n",
    "Output: scalar. If reduction is 'none', then (N, *)(N,∗) , same shape as input.\n",
    "\n",
    "***\n",
    "\n",
    "We want to apply the sigmoid function to the inputs to ensure they are in the 0 -> 1 range.\n",
    "\n",
    "We could also just use nn.BCE() which includes this.\n",
    "\n",
    "[A good example](https://jbencook.com/cross-entropy-loss-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6944d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# vis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0d48c",
   "metadata": {},
   "source": [
    "# Fake Dataset\n",
    "We need a fake dataset which contains lots of random 4 channel images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14992f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d54a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5863, 0.3891, 0.3761, 0.4355, 0.7719, 0.4832, 0.3970, 0.8288, 0.6467,\n",
       "        0.2531, 0.6923, 0.6348, 0.8546, 0.6840, 0.6340, 0.5333, 0.2957, 0.6036,\n",
       "        0.5755])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(torch.randn(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aee75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.m = nn.Sigmoid()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.randn([4, 512, 512])\n",
    "        label = self.m(torch.randn(19))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c6db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_dataset = CustomImageDataset(transform=None, target_transform=None)\n",
    "fake_loader = DataLoader(fake_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c3e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images, fake_labels = next(iter(fake_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f9dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 512, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e1ba07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 19])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3640c",
   "metadata": {},
   "source": [
    "As you can see we get random labels and images, our loss function may be all over the place but that prove it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70ce85",
   "metadata": {},
   "source": [
    "# Fake Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a008f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, NUM_CLASSES, DROPOUT_RATE):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.convolutions = nn.Sequential(nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "                                          *(list(resnet18().children())[1:-1]))\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        self.dense = nn.Linear(512, NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size = X.shape[0]\n",
    "        # Extracts 512x1 feature vector from pretrained resnet18 conv layers\n",
    "        x = self.convolutions(X).reshape(batch_size, -1)\n",
    "        # Fully connected dense layer to 19 class output\n",
    "        output = self.dense(self.dropout(x))\n",
    "        # Sigmoid activations on output to infer class probabilities\n",
    "        output_probs = self.out(output)\n",
    "        return output_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7623619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(19, 0.1)\n",
    "X = torch.randn([5, 4, 512, 512])\n",
    "\n",
    "pred = model(X)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef74ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4506, 0.3873, 0.4879, 0.3372, 0.7181, 0.4911, 0.6716, 0.4802, 0.4018,\n",
       "         0.3606, 0.4545, 0.3909, 0.7131, 0.4393, 0.4934, 0.4339, 0.3454, 0.2458,\n",
       "         0.4577],\n",
       "        [0.3775, 0.3640, 0.5062, 0.3624, 0.6508, 0.5775, 0.6875, 0.5595, 0.4165,\n",
       "         0.3349, 0.4511, 0.4914, 0.5917, 0.3830, 0.5156, 0.5523, 0.3053, 0.3024,\n",
       "         0.3714],\n",
       "        [0.4305, 0.3516, 0.5072, 0.3920, 0.7123, 0.5540, 0.7094, 0.5007, 0.4186,\n",
       "         0.3057, 0.4342, 0.4312, 0.6407, 0.4642, 0.4958, 0.4602, 0.3474, 0.3059,\n",
       "         0.4123],\n",
       "        [0.4481, 0.4034, 0.4698, 0.4349, 0.7337, 0.6202, 0.6727, 0.5569, 0.4566,\n",
       "         0.3851, 0.4531, 0.4501, 0.6514, 0.4018, 0.5933, 0.4485, 0.3363, 0.3049,\n",
       "         0.4045],\n",
       "        [0.4250, 0.3600, 0.4252, 0.4092, 0.6391, 0.6368, 0.6691, 0.5495, 0.3576,\n",
       "         0.3608, 0.4237, 0.5830, 0.6398, 0.4901, 0.5555, 0.4593, 0.3972, 0.2662,\n",
       "         0.3964]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bfdde",
   "metadata": {},
   "source": [
    "# Fake Loss Function\n",
    "Using fake model, let's get the fake loss function working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5acadc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684eb343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 19])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we have to make fake Ground Truths\n",
    "ground_truth = torch.full((5, 19), 1)\n",
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c891ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8279be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7839, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute loss \n",
    "loss = loss_fn(pred, ground_truth.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4d3cb",
   "metadata": {},
   "source": [
    "We then can use loss.backward() to update the change in loss for the weights.\n",
    "\n",
    "<code>loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. In pseudo-code:\n",
    "\n",
    "x.grad += dloss/dx\n",
    "optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "x += -lr * x.grad\n",
    "optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f9eba",
   "metadata": {},
   "source": [
    "# Fake Optimiser\n",
    "\n",
    "N.B In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. This is convenient while training RNNs. So, the default action is to accumulate (i.e. sum) the gradients on every loss.backward() call.\n",
    "\n",
    "Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Else the gradient would point in some other direction than the intended direction towards the minimum (or maximum, in case of maximization objectives).\n",
    "\n",
    "[Why Choose Adam](https://debuggercafe.com/adam-algorithm-for-deep-learning-optimization/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c588cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001) # we could put a scheduler here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26a51b",
   "metadata": {},
   "source": [
    "When we use te optimizer what we are doing is [because](https://deeplearningdemystified.com/article/fdl-4) we want to avoid certain traps in achieving minimal loss (local optima, changing how certain weights are updated).\n",
    "\n",
    "To use the optimiser we first initialize (as above) and and then in the training loop:\n",
    "\n",
    "<code>#Backpropagation\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-bradley",
   "metadata": {},
   "source": [
    "# Fake Accuracy\n",
    "\n",
    "To calculate accuracy we add up all the 'correct' guesses and divide by len of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sexual-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19])\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "southeast-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19])\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "located-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(fake_loader.dataset) # in actual thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "peripheral-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "correct += torch.sum((pred >= 0.5).float() == ground_truth.float()).item()\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sound-coalition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3157894736842105"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc = correct / size * 19 labels\n",
    "acc = correct / (5 * 19)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2627a03",
   "metadata": {},
   "source": [
    "# Fake Training Loop\n",
    "Using fake inputs and predicitons I am going to show what the training loop should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7963952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optim, dataloader, loss_fn, USE_GPU=False):\n",
    "    # How Long is our dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Firstly set model to training\n",
    "    model.train()\n",
    "    # if we are using a GPU send the model to device\n",
    "    if USE_GPU:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    # Set gradients to be trainable\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for batch_num, (X,y) in enumerate(dataloader):\n",
    "            # If cuda send to cuda\n",
    "            if USE_GPU:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Logging and Stats\n",
    "            if batch_num % 100 == 0:\n",
    "                loss, current = loss.item(), batch_num * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b12b3c0",
   "metadata": {},
   "source": [
    "# Fake Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3d742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, optim, dataloader, loss_fn, USE_GPU=False):\n",
    "    # How long is our dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # model testing\n",
    "    model.eval()\n",
    "    \n",
    "    if USE_GPU:\n",
    "        model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            if USE_GPU:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "                \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += torch.sum((pred >= 0.5).float() == y.float()).item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= (size * 19)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return(correct, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27fccc",
   "metadata": {},
   "source": [
    "# Fake Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1d636fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# batch size\n",
    "batch_s = 4\n",
    "\n",
    "# train dataset & dataloader\n",
    "dataset_train = torch.utils.data.Subset(fake_dataset, \n",
    "                                        list(range(0,800)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                          batch_size=batch_s,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# test dataset & dataloader\n",
    "dataset_test = torch.utils.data.Subset(fake_dataset,\n",
    "                                     list(range(800, len(fake_dataset))))\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"test\": test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01497219",
   "metadata": {},
   "source": [
    "# Fake Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbeede76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.728572  [    0/  800]\n",
      "loss: 0.699750  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.695331 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.696597  [    0/  800]\n",
      "loss: 0.694911  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.696680 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.697246  [    0/  800]\n",
      "loss: 0.703069  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.700408 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.694764  [    0/  800]\n",
      "loss: 0.700051  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.697117 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.702744  [    0/  800]\n",
      "loss: 0.694605  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.694703 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "EPOCHS = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "best_acc = 0.0\n",
    "log_acc = list()\n",
    "log_loss = list()\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(model, optimizer, dataloaders['train'], loss_fn, USE_GPU=True)\n",
    "    correct, test_loss = test_loop(model, optimizer, dataloaders['test'], loss_fn, USE_GPU=True)\n",
    "    log_acc.append(correct)\n",
    "    log_loss.append(test_loss)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "national-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss/ Acc over Epochs')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, len(log_loss), 1), log_loss, color='g')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('# of Epochs')\n",
    "plt.title('Loss/ Acc over Epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell]",
   "language": "python",
   "name": "conda-env-cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
