{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cab3826",
   "metadata": {},
   "source": [
    "# Fake Training\n",
    "\n",
    "For our problem we have the output from the model as:\n",
    "\n",
    "$[N, C]$\n",
    "\n",
    "And our labels are one hot encoding are the same:\n",
    "\n",
    "$[N, C]$ \n",
    "\n",
    "where N is the number of samples, C is either {1, 0}.\n",
    "\n",
    "In PyTorch torch.nn.BCELoss() is [Binary Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html):\n",
    "\n",
    "Which expects the input:\n",
    "\n",
    "***\n",
    "\n",
    "Input: (N, *)(N,∗) where *∗ means, any number of additional dimensions\n",
    "\n",
    "Target: (N, *)(N,∗) , same shape as the input\n",
    "\n",
    "Output: scalar. If reduction is 'none', then (N, *)(N,∗) , same shape as input.\n",
    "\n",
    "***\n",
    "\n",
    "We want to apply the sigmoid function to the inputs to ensure they are in the 0 -> 1 range.\n",
    "\n",
    "We could also just use nn.BCE() which includes this.\n",
    "\n",
    "[A good example](https://jbencook.com/cross-entropy-loss-in-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6944d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# vis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0d48c",
   "metadata": {},
   "source": [
    "# Fake Dataset\n",
    "We need a fake dataset which contains lots of random 4 channel images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14992f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d54a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2974, 0.5517, 0.5088, 0.5314, 0.6474, 0.4521, 0.4651, 0.4481, 0.2105,\n",
       "        0.1856, 0.7935, 0.5610, 0.3532, 0.5682, 0.4106, 0.8076, 0.5290, 0.3781,\n",
       "        0.2804])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(torch.randn(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aee75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.m = nn.Sigmoid()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.randn([4, 512, 512])\n",
    "        label = self.m(torch.randn(19))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c6db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_dataset = CustomImageDataset(transform=None, target_transform=None)\n",
    "fake_loader = DataLoader(fake_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c3e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images, fake_labels = next(iter(fake_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f9dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 512, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51e1ba07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 19])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3640c",
   "metadata": {},
   "source": [
    "As you can see we get random labels and images, our loss function may be all over the place but that prove it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f70ce85",
   "metadata": {},
   "source": [
    "# Fake Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a008f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, NUM_CLASSES, DROPOUT_RATE):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.convolutions = nn.Sequential(nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "                                          *(list(resnet18().children())[1:-1]))\n",
    "        self.dropout = nn.Dropout(DROPOUT_RATE)\n",
    "        self.dense = nn.Linear(512, NUM_CLASSES)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size = X.shape[0]\n",
    "        # Extracts 512x1 feature vector from pretrained resnet18 conv layers\n",
    "        x = self.convolutions(X).reshape(batch_size, -1)\n",
    "        # Fully connected dense layer to 19 class output\n",
    "        output = self.dense(self.dropout(x))\n",
    "        # Sigmoid activations on output to infer class probabilities\n",
    "        output_probs = self.out(output)\n",
    "        return output_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7623619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 19])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(19, 0.1)\n",
    "X = torch.randn([5, 4, 512, 512])\n",
    "\n",
    "pred = model(X)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef74ad2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3839, 0.5203, 0.7406, 0.4206, 0.4875, 0.5890, 0.4729, 0.6067, 0.6170,\n",
       "         0.2123, 0.5601, 0.6549, 0.5149, 0.5089, 0.4273, 0.4545, 0.4972, 0.3334,\n",
       "         0.5236],\n",
       "        [0.3370, 0.6401, 0.7354, 0.4536, 0.5475, 0.5224, 0.4980, 0.6303, 0.5895,\n",
       "         0.2521, 0.5355, 0.6369, 0.4139, 0.5471, 0.3970, 0.4957, 0.5010, 0.3926,\n",
       "         0.4911],\n",
       "        [0.4606, 0.6381, 0.7047, 0.3945, 0.4880, 0.5686, 0.4060, 0.6608, 0.5578,\n",
       "         0.3162, 0.5196, 0.6032, 0.4896, 0.5697, 0.3799, 0.4580, 0.5451, 0.3684,\n",
       "         0.5342],\n",
       "        [0.4146, 0.5901, 0.7612, 0.3581, 0.5148, 0.6330, 0.4894, 0.6079, 0.5471,\n",
       "         0.2241, 0.5006, 0.6214, 0.3935, 0.5241, 0.4513, 0.5181, 0.5179, 0.3387,\n",
       "         0.4520],\n",
       "        [0.4193, 0.6261, 0.7751, 0.4414, 0.5079, 0.6156, 0.3594, 0.6344, 0.6109,\n",
       "         0.2686, 0.5411, 0.6542, 0.3818, 0.5344, 0.3840, 0.4987, 0.5667, 0.4543,\n",
       "         0.5526]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bfdde",
   "metadata": {},
   "source": [
    "# Fake Loss Function\n",
    "Using fake model, let's get the fake loss function working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5acadc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684eb343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 19])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we have to make fake Ground Truths\n",
    "ground_truth = torch.full((5, 19), 1)\n",
    "ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c891ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8279be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7097, grad_fn=<BinaryCrossEntropyBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute loss \n",
    "loss = loss_fn(pred, ground_truth.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4d3cb",
   "metadata": {},
   "source": [
    "We then can use loss.backward() to update the change in loss for the weights.\n",
    "\n",
    "<code>loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. In pseudo-code:\n",
    "\n",
    "x.grad += dloss/dx\n",
    "optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:\n",
    "x += -lr * x.grad\n",
    "optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f9eba",
   "metadata": {},
   "source": [
    "# Fake Optimiser\n",
    "\n",
    "N.B In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. This is convenient while training RNNs. So, the default action is to accumulate (i.e. sum) the gradients on every loss.backward() call.\n",
    "\n",
    "Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Else the gradient would point in some other direction than the intended direction towards the minimum (or maximum, in case of maximization objectives).\n",
    "\n",
    "[Why Choose Adam](https://debuggercafe.com/adam-algorithm-for-deep-learning-optimization/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9c588cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0001) # we could put a scheduler here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26a51b",
   "metadata": {},
   "source": [
    "When we use te optimizer what we are doing is [because](https://deeplearningdemystified.com/article/fdl-4) we want to avoid certain traps in achieving minimal loss (local optima, changing how certain weights are updated).\n",
    "\n",
    "To use the optimiser we first initialize (as above) and and then in the training loop:\n",
    "\n",
    "<code>#Backpropagation\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-bradley",
   "metadata": {},
   "source": [
    "# Fake Accuracy\n",
    "\n",
    "To calculate accuracy we add up all the 'correct' guesses and divide by len of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "sexual-transparency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19])\n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "southeast-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 19])\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(dataloader.dataset) # in actual thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "peripheral-proposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "correct += torch.sum((pred >= 0.5).float() == ground_truth.float()).item()\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sound-coalition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5473684210526316"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc = correct / size * 19 labels\n",
    "acc = correct / (5 * 19)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2627a03",
   "metadata": {},
   "source": [
    "# Fake Training Loop\n",
    "Using fake inputs and predicitons I am going to show what the training loop should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7963952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optim, dataloader, loss_fn, USE_GPU=False):\n",
    "    # How Long is our dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    # Firstly set model to training\n",
    "    model.train()\n",
    "    # if we are using a GPU send the model to device\n",
    "    if USE_GPU:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # Logging and Stats\n",
    "    loss_log = list()\n",
    "    \n",
    "    # Set gradients to be trainable\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for batch_num, (X,y) in enumerate(dataloader):\n",
    "            # If cuda send to cuda\n",
    "            if USE_GPU:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            # Compute prediction and loss\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Logging and Stats\n",
    "            if batch_num % 100 == 0:\n",
    "                loss, current = loss.item(), batch_num * len(X)\n",
    "                loss_log.append(loss)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "                \n",
    "    return(loss_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b12b3c0",
   "metadata": {},
   "source": [
    "# Fake Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3d742c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, optim, dataloader, loss_fn, USE_GPU=False):\n",
    "    # How long is our dataset\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # model testing\n",
    "    model.eval()\n",
    "    \n",
    "    if USE_GPU:\n",
    "        model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            if USE_GPU:\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "                \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += torch.sum((pred >= 0.5).float() == y.float()).item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= (size * 19)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27fccc",
   "metadata": {},
   "source": [
    "# Fake Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d636fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# batch size\n",
    "batch_s = 4\n",
    "\n",
    "# train dataset & dataloader\n",
    "dataset_train = torch.utils.data.Subset(fake_dataset, \n",
    "                                        list(range(0,800)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                          batch_size=batch_s,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# test dataset & dataloader\n",
    "dataset_test = torch.utils.data.Subset(fake_dataset,\n",
    "                                     list(range(800, len(fake_dataset))))\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)\n",
    "print(len(dataset_train))\n",
    "print(len(dataset_test))\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"test\": test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01497219",
   "metadata": {},
   "source": [
    "# Fake Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbeede76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.687477  [    0/  800]\n",
      "loss: 0.691842  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.694582 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.696447  [    0/  800]\n",
      "loss: 0.692596  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.696067 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.693917  [    0/  800]\n",
      "loss: 0.695454  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.695584 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.694453  [    0/  800]\n",
      "loss: 0.696476  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.698328 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.702428  [    0/  800]\n",
      "loss: 0.690511  [  400/  800]\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 0.698118 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "EPOCHS = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "best_acc = 0.0\n",
    "log = list()\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_log = train_loop(model, optimizer, dataloaders['train'], loss_fn, USE_GPU=True)\n",
    "    log = log + loss_log\n",
    "    test_loop(model, optimizer, dataloaders['test'], loss_fn, USE_GPU=True)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "national-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss over Epochs')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, len(loss_log), 1), loss_log)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('# of Epochs')\n",
    "plt.title('Loss over Epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cell]",
   "language": "python",
   "name": "conda-env-cell-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
